%\vspace{-0.1in}
\section{Secure code partitioning}
\label{sec:pipe}

\newcommand{\prog}{s}
\newcommand{\progn}{t}
\newcommand{\mprog}{u}
\newcommand{\seq}{||}
\newcommand{\stateq}{q}

In this section, we describe our ``secure code partitioning'' technique that
allows \tool to execute programs that require large circuits. The reason to implement partitioning is as follows: when compiling from a high level functionality to a circuit being evaluated securely, the circuits so generated can quite often be larger than the total memory available on the machines executing 2PC. The secure protocol for evaluating this circuit cannot then be generated without swapping the circuit in and out of main memory, thereby causing large slowdowns (see Section \ref{sec:pipeeval}). In order to avoid this problem, we ``split'' the high level functionality into smaller programs that compile into small circuits whose secure evaluation can completely fit into main memory. These smaller circuits are then evaluated sequentially to evaluate the entire program. Naturally, care must be taken to ensure that the partial evaluation of these circuits do not reveal any more information than the final output of the overall functionality. More details follow.

Our techniques take inspiration from the idea of pipelining Yao's garbled circuits described in FastGC \cite{yao-pipe}.
However, unlike FastGC, we do not operate at a circuit level and partitioning is independent of the specific
\mpc protocol. 
Let $\prog$ be a program in our source language that
generates a circuit $\crct$. For some programs, the circuit $\crct$
can be larger than
the memory size\footnote{In fact, there is
  an upper limit of $2^{32}-1$ gates for the circuit size in ABY but
  for most machines the memory limit is hit first.} and fail to
execute. Partitioning enables us to 
execute such programs via a source to source transformation that is
oblivious to the underlying \mpc backend. Partitioning decomposes the
program $\prog$ into a sequence of smaller \tool programs
$\progn_1,\progn_2,\ldots,\progn_k$ (as defined below) such
that the circuit size
requirement for each of the $\progn_i$ itself is manageable. We compile
and execute each $\progn_i$ sequentially, feeding the outputs of
$\progn_i$ as state
information to $\progn_{i+1}$. We prove our partitioning scheme to be
correct ($\prog$ and sequential execution of $\progn_1,\progn_2,\ldots,\progn_k$ compute
the same functionality) and secure (sequential execution of
$\progn_1,\progn_2,\ldots,\progn_k$ does
not reveal any more information than $\prog$). 
%
%Prior works such as FastGC \cite{yao-pipe} and ObliVM \cite{oblivm} have developed similar techniques specific to garbled circuits that work at the level of circuits.
%
%considered the idea of pipelining of circuits for secure computation based on Yao's garbled circuits that allows them to scale to large circuits. Our technique of secure code partitioning works with high level programs and does source code transformation. This gives a generic way to execute programs with large underlying circuits (even a mix of arithmetic and Boolean) and is not tied to the specific details of the cryptographic protocol used.
%}
More formal details follow, while an example illustrating the technique of secure code partitioning is provided in the full version. %\appendixref{codepartitioning}. 

Let $\prog$ be a program that takes (secret) inputs $x$ from Alice and
$y$ from Bob and produces an output $z$ to both parties. Let
$\prog_1\seq\prog_2\seq\dots\seq\prog_k$ be a decomposition of $\prog$
such that the following holds. Define $\stateq_0 = \bot$ (the public empty
state). For all
$1\leq i\leq k-1$, $\prog_i$ takes inputs $x, y$ and $\stateq_{i-1}$ and
outputs state $\stateq_i$. Finally, $\prog_k$ takes inputs $x, y$ and
$\stateq_{k-1}$ to  output $z$. It is
possible to decompose any program $\prog$  into such
$\prog_1\seq\prog_2\seq\dots\seq\prog_k$. If \tool generates circuit
$\crct_i$ from
$\prog_i$, the parties can execute
$\crct_1, \crct_2, \dots \crct_k$
sequentially (in a distributed setting)  to obtain
$\stateq_1,\dots,\stateq_{k-1},$ and finally output $z$. At the
$i^{\textrm{\tiny{th}}}$ step, the parties only need to store
information proportional to $x,y,\stateq_{i-1}$ and $\crct_i$ (which is
much smaller than $\crct$). However, this execution enables the
parties to learn $\stateq_i$ (for all $1\leq i\leq k-1$), which
completely breaks the security.

To overcome this problem, we define a sequence of new programs
$\progn_i$ ($1\leq i\leq k$) as follows. Once again, define $\stateq_0
= \bot$. Without
loss of generality, let all $\stateq_i$ be values in some additive ring
$(\mathbb{Z},+)$ (e.g., the additive ring $(\mathbb{Z}_{2^{64}},+)$,
i.e., the additive ring of integers modulo $2^{64}$).
Let $r_1,\cdots,r_{k-1}$ be a sequence of random values sampled from
the same ring $(\mathbb{Z},+)$ by Alice (in our implementation, all
$r_i$ values are generated by a pseudorandom function). Let $\progn_1$
be the program that takes as input $x,r_1$ from Alice and $y$ from Bob
(and empty state $\stateq_0$), and runs $\prog_1$ (as defined above) to
compute $\stateq_1$ and then outputs $o_1 = \stateq_1 + r_1$ {\em only
  to} Bob\footnote{While the description of the scheme here assumes
  that
  the underlying backend supports only one party receiving output,
  this is only a simplifying assumption, and we can easily modify our
  protocol in the case where both parties must receive the same
  output. %To do so, we modify $\progn_1$ to output $o_1 = s_1+r_1+r'_1$ to
  %both parties (where $r'_1$ is random and chosen by Bob). We can then
  %appropriately modify the remaining steps as well.
 }. 
  Alice's output
from $\progn_1$ is $r_1$. Next, every $\progn_i$ ($2\leq i\leq k-1$)
takes as inputs $x,r_{i-1},r_i$ from Alice and $y,o_{i-1}$ from Bob,
runs $\prog_i$
on inputs $x,y$ and state $\stateq_{i-1} = (o_{i-1}-r_{i-1})$ (where $-$ denotes
subtraction in the ring $(\mathbb{Z},+)$) and then outputs $\stateq_i+r_i$
to Bob and $r_i$ to Alice. The last
program $\progn_k$ takes inputs $x,y,r_{k-1},o_{k-1}$, runs $\prog_k$
on inputs $x,y$ and state $\stateq_{k-1} = (o_{k-1}-r_{k-1})$ and outputs $z$ to both
parties. Although we have used arithmetic sharing here, Boolean sharing can be used to achieve the same effect.

Thus, given a decomposition of $\prog$ into
$\prog_1\seq\prog_2\seq\dots\seq\prog_k$, we can use the construction
above to generate programs $\progn_1,\progn_2,\ldots,\progn_k$, that
can be sequentially executed, using the unmodified underlying \mpc
backend. We prove the following theorem for code partitioning:

%% \paragraph{Security.} The following theorem states the correctness and security of
%% code partitioning.

\begin{theorem}[Correctness and security of partitioning]
If $\prog_1||\prog_2||\ldots||\prog_k$ is a decomposition of a program $\prog$, then there exists a sequence of programs $\progn_1, \progn_2, \ldots, \progn_k$ and protocols $\prot_1, \prot_2, \ldots, \prot_k$ such that for all $i$, $\prot_i$ securely realizes $\progn_i$ and  $\prot
= \prot_1,\prot_2,\dots,\prot_k$ securely realizes $s$.
\end{theorem}

\noindent {\em Proof.} Let $\progn_1, \ldots, \progn_k$ be the
sequence of programs as defined above corresponding to the
decomposition $\prog = \prog_1||\prog_2||\ldots||\prog_k$.  For every
$1\leq i\leq k$, let $\prot_i$ be the \mpc protocol output by our
framework for $\progn_i$. Our construction for programs $\progn_i$
ensures that if $\prog$ is well-typed, then for each $1\leq i \leq k$,
$\progn_i$ is well-typed. By \theoremref{security}, $\prot_i$,
the \mpc protocol that evaluates the circuit generated by $\progn_i$,
securely realizes $\progn_i$. That is, for every $1\leq i \leq k-1$,
the $\prot_i$ provides observations $r_i$ to Alice and $o_i$
to Bob. Protocol $\prot_k$ provides observation $z$ to both Alice
and Bob. Finally, since $r_i$ and $o_i$ ($1\leq i\leq k-1$) are
individually uniformly random (in $(\mathbb{Z},+)$, outputs received
by the adversary can be simulated given the final output $z$.


%\begin{theorem}[Correctness and security of partitioning]
%Let $\prog$ be a program in our source language with output $z$, that
%is decomposed into programs
%$\prog'_1\seq\prog'_2\seq\dots\seq\prog'_k$ (as defined in
%the partioning procedure above) and compiled into the protocol $\prot
%= \prot_1\seq\prot_2\dots\seq\prot_k$ that outputs $r_1\seq
%r_2\seq\dots\seq z$ 
%(to Alice) and $o_1\seq o_2\seq\dots||z$ (to Bob), then $\prot$ securely
%realizes $P$.
%\end{theorem}
%
%\noindent {\em Proof.} From \theoremref{security}, it follows that
%$\prot_i$ securely realizes $\prog'_i$ for every $1\leq i\leq
%k$. Hence, we know that the only information learnt by Alice is
%$r_1||r_2||\cdots||r_{k-1}||z$ and by Bob is
%$o_1||o_2||\cdots||o_{k-1}||z$. Since $r_i$ and $o_i$ ($1\leq i\leq
%k-1$) are individually uniformly random (in $(\mathbb{Z},+)$, outputs
%received by the adversary can be easily simulated given the final
%output $z$.

\noindent\textbf{Implementing code partitioning.}
We use partitioning for programs that require large
circuits. Specifically, we first decompose the program
$\prog$ into a sequence of small programs
$\prog_1\seq\dots\seq\prog_k$. And then, \tool generates
sequence of programs $\progn_1,\dots\progn_k$ automatically. We then
compile and execute the $k$ programs
$\progn_1,\progn_2,\ldots,\progn_k$ sequentially, freeing up memory
usage after execution of each $\progn_i$.
Automating the  decomposition step requires an analysis that can 
statically estimate the resource usage of a \tool program.
Resource analysis of high-level programs is a well-known hard problem~\cite{raml}
and we describe a heuristic analysis.

To build $s_1$, we consider the longest
prefix of $s$ whose computation {\it size} is below the threshold enforced by the available memory of the machine.
If $\prog = \prog_1; \prog_r$ then we recurse on $\prog_r$ to obtain $\prog_2,\ldots,\prog_k$.
For a program $\mprog$, to estimate ${\it size}(\mprog)$, we need to discuss three important cases: if $\mprog\equiv\mprog_1;\mprog_2$
then ${\it size}(\mprog)={\it size}(\mprog_1)+{\it size}(\mprog_2)$; if $\mprog\equiv\ite{e_1}{\mprog_1}{\mprog_2}$ then ${\it size}(\mprog)=\max({\it size}(\mprog_1),{\it size}(\mprog_2))$; if $s\equiv\forl{i}{n_1}{n_2}{\mprog_1}$ then
${\it size}(\mprog)=(n_2-n_1){\it size}(\mprog_1)$. If $(n_2-n_1){\it size}(\mprog_1)$ is above the threshold then
we replace $\mprog$ by 
\[\forl{i}{n_1}{\frac{n_1+n_2}{2}}{\mprog_1}; \forl{i}{\frac{n_1+n_2}{2}}{n_2}{\mprog_1}\]
 and recurse to find the prefix again.
This heuristic analysis is sufficient for the benchmarks discussed in our evaluation.

We stress that partitioning is fully automated and is compatible with any 2PC protocol. Furthermore, the \tool compiler, with suitable changes to operator costs, can target other backends including 3PC or MPC, or protocols secure against malicious adversaries.
 
% \nc{I changed the heading.}


