\section{Evaluation}
\label{sec:eval}

We first implement benchmarks of ~\cite{shafindss} and~\cite{minionn} in \tool.
Next, we show the generality of \tool by implementing state-of-the-art machine learning models.
Finally, we discuss a model that requires pipelinig.
Our results are in two settings, a LAN setting and a cross-continent WAN setting.
The round trip time for two machines in a LAN setting is 1ms and in WAN setting is 40ms.

\subsection{Standard models}
\label{sec:shallow}
We consider three types of classifiers: linear, Naive Bayes, and decision trees. 
These classifiers are trained on the followinng data sets from the UCI  machine learning repository:
 the Wisconsin Breast Cancer data set, 
Credit Approval data set, Audiology (Standardized) data set, Nursery data set, and
ECG (electrocardiogram) classification data from~\cite{barni}.

For a  (binary) linear classifier of model size $n$ we output $w^Tx>0$ where $w$ and $x$ are vectors
of length $n$. In Naive Bayes classification, we are given a vector $P$ of log-probabilities
$\log p(C=c_i)$, where $p(C=c_i)$ is the likelihood that the output class is $c_i$ for $i\in[n]$. 
We are also given a matrix $T$ s.t. $T[i][j]=\log p(X_j=x_j|C=c_i)$, i.e., the log-probability that 
the $j^{th}$ input feature is $x_j$ (where $j\in [d]$) given that the output class is $c_i$. The output is
\[
{\it argmax}_i P[i]+\sum_{j=1}^d\log p(X_j=x_j|C=c_i)
\]
A decision tree has a boolean predicate $b_i(x) = x_i\leq w_i$ at each internal node and classes as leaves.
We start from root and if $b_i(x)$ evaluates to true then we go to the right node else
we go to the right node. This process is repeated until we reach a leaf that provides
the predicted label. Such a decision tree can be encoded as a polynomial and then prediction
reduces to polynomial evaluation. E.g., a tree with depth one can be encoded as the polynomial
$(1-b(x))c_l + b(x)c_r$ where $b(x)$ is the predicate at the root, $c_l$ is the label of the left leaf
and $c_r$ is the label of the right leaf. The trees in our benchmark set have a depth of 4.

\begin{table*}
\begin{tabular}{c|c|c|c|c |c|c|c|c|c|c}
Dataset & $n$  & Prev. time (s) & Prev. Comm (kb) & LAN time (s) & WAN time (s) & Comm. (kb)  & \#And & \#Mul & \#Gates & size\\
\hline
Breast cancer & 30 & 0.3 & 36 & 0.1 & 0.3 & 25 & 95 & 30 & 727 & 20\\
\hline
Credit & 47 & 0.3 & 41 & 0.1 & 0.3 & 36 & 95 & 47 & 795 & 20\\
\hline
\end{tabular}

 \caption{Linear classification benchmarks}
 \label{tab:lc} 
\end{table*}

\begin{table*}
\begin{tabular}{c|c|c|c|c|c |c|c|c|c|c|c}
Dataset & $|P|$ & $|x|$ & Prev. time (s) & Prev. Comm (Mb) & LAN time (s) & WAN time (s) & Comm. (Mb)  & \#And & \#Mul & \#Gates  & size\\
\hline
Nursery & 5 & 9 & 1.5 & 0.2 & 0.1 & 0.4 & 0.6 & 13k & 0 & 73k & 50\\
\hline
Audiology & 24 & 70 & 3.9 & 2.0 & 1.5 & 2.9 & 37 & 750k & 0 & 4219k & 50\\
\hline
\end{tabular}

 \caption{Naive Bayes benchmarks}
 \label{tab:nb} 
\end{table*}

\begin{table*}
\begin{tabular}{c|c|c|c |c|c|c|c|c|c}
Dataset  & Prev. time (s) & Prev. Comm (kb) & LAN time (s) & WAN time (s) & Comm. (kb)  & \#And & \#Mul & \#Gates & size\\
\hline
Nursery &  0.3 & 102 & 0.1 & 0.3 & 32 & 504 & 3 & 3324 & 20\\
\hline
ECG &  0.4 & 102 & 0.1 & 0.4 & 49 & 756 & 5 & 5002 & 20\\
\hline
\end{tabular}

 \caption{Decision tree benchmarks}
 \label{tab:dt} 
\end{table*}


%dataset  | size | gates | and | mul | depth | length

%dataset | time | comm | timeL | timeW | comm
\subsection{Neural networks}
We evaluate on the benchmarks described in \minion~\cite{minionn}.
The first is the neural network described in SecureML~\cite{secureml}.
It has three fully connected layers with square as the activation function.
Next, we implement the neural network of Cryptonets~\cite{cryptonets} in \tool.
This network also uses square as the activation function and has one convolution (with 5 output channels), one maxpool, and one fully connected layer.
Finally, we compare against\minion on a convolutional neural network
with two convolutions (with 16 output channels), two maxpool, and two fully connected layers.
In contrast to the previous two, this network uses ReLU for activation.
In our results, we only compare with \minion, as it outperforms the earlier systems of
Cryptonets and SecureML.
%net | minionT | minionC | timeL | timeW | comm | gates | and | mul | length 

\begin{table*}
\begin{tabular}{c|c|c|c |c|c|c|c|c|c}
Name  & Prev. time (s) & Prev. Comm (Mb) & LAN time (s) & WAN time (s) & Comm. (Mb)  & \#And & \#Mul & \#Gates & size\\
\hline
SecureML   &  1.1 & 15.8 & 0.7 & 1.7  & 76   &  2k   & 119k & 366k   & 78\\
\hline
Cryptonets &  1.3 & 47.6 & 0.6 & 1.6  & 7    & 2k    & 108k & 316k & 88\\
\hline
CNN        &  9.4 & 657.5& 5.1 & 11.6 & 501  & 1640k & 667k & 9480k & 154\\
\hline
\end{tabular}

 \caption{Neural network benchmarks}
 \label{tab:nn} 
\end{table*}


\subsection{Practical models}
Tensorflow~\cite{tensorflow} is a standard machine learning toolkit.
Its tutorial describes two prediction models for handwritten digit recognition
using the MNIST dataset~\cite{mnist} which has 55,000 images as training data,
10,000 images as test data (mnist.test), and 5,000 images as validation data.
Each image is a greyscale image of size $28\times 28$.
The first model that the tutorial describes is a softmax regression
which provides an accuracy of 92\%. Since this model is over floating-point,
as is standard~\cite{secureml,minionn}, we port it to a model over 32-bit integers manually. After our port, the accuracy is still preserved.
Next, we implement this model in \tool and the results are shown below.

The next model in the Tensorflow tutorial is a convolution neural net with two convolutions
(with 32 output channels), two maxpool, and two fully connected layers.
This network is both bigger and more accurate than the networks presented in the previous section.
In particular, it has an accuracy of 99.2\%. Again, since this model is in floating-point,
we port it to integers while maintaining the accuracy\footnote{The accuracy of the integer model is 0.04\% higher than the floating-point model.}.

% benchmark | size | gates | and | mul | depth  | length | comm | timeL | timeW

\begin{table*}
\begin{tabular}{c|c|c|c |c|c|c|c|c|c | c}
Name       & LAN time (s) & WAN time (s) & Comm. (Mb)  & \#And & \#Mul & \#Gates & Model size & Program size\\
\hline
Regression &  0.1         & 0.7         & 5            & 2k    & 8k    &  35k    & 8k   & 38\\
\hline
CNN        &  30.5        & 60.3        & 2955         & 6082k & 4163k &  42104k & 3226k& 172\\
\hline
\end{tabular}

 \caption{Tensorflow tutorial benchmarks}
 \label{tab:tf} 
\end{table*}


Finally, there are a class of machine learning models that are much more efficient than
deep neural nets and provide good accuracies on standard learning tasks. One such model
is \bonsai~\cite{bonsai}, which is a decision tree with more powerful nodes.
In particular, each node $m_k$ evaluates a predicate $\theta_k^TZx > 0$ to decide whether
to pass $x$ to the left branch or the right branch. and the predicted value is
\[
{\it argmax} \sum_k I_k(x)W_k^TZx\circ f(\sigma V_k^TZx) 
\]
Here, $I_k$ is 1 if the $k^{th}$ node is present on the path traversed by $x$
and is zero otherwise. 
The operation $\circ$ is a pointwise dot product and
the function $f$ is given by $f(x) = x$ if $|x| < 1$ and $\mathrm{signum}(x)$ otherwise.
We show results on three standard data sets: character  (Chars4k~\cite{campos}), text (USPS~\cite{hull}), and object categorization (WARD~\cite{yang}). There are other other benchmarks in~\cite{bonsai} that do not add any new insights here. Moreover, the dataset WARD requires the largest model. These models are already over integers and no port from floating-point is required.
%dataset | size | gates | and | mul | depth | length | comm | timeL | timeW


\begin{table*}
\begin{tabular}{c|c|c|c |c|c|c|c|c|c | c}
Name       & LAN time (s) & WAN time (s) & Comm. (Mb)  & \#And & \#Mul & \#Gates & depth & Program size\\
\hline
Chars4k    &  0.1         & 0.7         & 2            & 18k    & 3k    &  85k     & 1   & 89\\
\hline
USPS       &  0.2         & 0.9         & 4            & 62k    & 2k    &  285k    & 2   & 156\\
\hline
WARD       &  0.3         & 1.1         & 9            & 106k    & 8k    &  506k    & 3   & 283\\
\hline
\end{tabular}

 \caption{Bonsai benchmarks}
 \label{tab:bonsai} 
\end{table*}

\subsection{Pipelining}
The largest benchmark of \minion is a neural network for CIFAR-10 dataset~\cite{cifar}: label colored images for objects in 10 classes. This network needs more memory than what is available
on our machines. Therefore, we use pipelining and divide the computation into seven stages.
The first step does a convolution with 64 output channels and a ReLU activation.
The next four stages perform a convolution that involves multiplying a $64\times 576$ matrix with a
$576\times 1024$ matrix. The next stage performs a ReLU, a meanpool, and a convolution.
The final stage performs four convolutions, a mean pool, five ReLU and a fully connected layer.
The results show the end-to-end results as well as the statistics for the heaviest stage.
In contrast, \minion takes 544 seconds and 9272 Mb for this model. As before, we are faster than
\minion in the LAN setting and slower in the WAN setting.

\begin{table*}
\begin{tabular}{c|c|c|c |c|c|c}
           &  LAN time (s) & WAN time (s) & Comm. (Mb)  & \#And & \#Mul & \#Gates \\
\hline
Total      &  265.6       & 647.5        & 40683       & 21m    & 61m    &  337m  \\
\hline
Stage 6    &  55.2        & 122.6        & 6744        & 12m    & 10m   &  98m  \\
\hline
\end{tabular}

 \caption{Pipelining results}
 \label{tab:cifar} 
\end{table*}

%stage | time | comm | gates | mul | add | depth